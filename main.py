import streamlit as st # pip install streamlit
import openai # pip install openai
import pandas as pd # pip install pandas
import os
import requests
import json
import cv2
import whisper
import subprocess
import requests

from dotenv import load_dotenv # pip install python-dotenv
from deepface import DeepFace
from collections import Counter
from bs4 import BeautifulSoup

load_dotenv()

# OpenAI API ì„¤ì •
openai.api_key = os.getenv("OPENAI_API_KEY")
openai.azure_endpoint = os.getenv("AZURE_OPENAI_ENDPOINT")
openai.api_type = os.getenv("OPENAI_API_TYPE")
openai.api_version = os.getenv("OPENAI_API_VERSION")

embedding_api_key = os.getenv("EMBEDDING_OPENAI_API_KEY")
embedding_azure_endpoint = os.getenv("EMBEDDING_AZURE_OPENAI_ENDPOINT")
embedding_api_type = os.getenv("EMBEDDING_OPENAI_API_TYPE")
embedding_api_version = os.getenv("EMBEDDING_OPENAI_API_VERSION")

embedding_deployment = os.getenv("EMBEDDING_DEPLOYMENT_NAME")
search_api_key = os.getenv("AZURE_SEARCH_API_KEY")
search_endpoint = os.getenv("AZURE_SEARCH_ENDPOINT")
search_index = os.getenv("AZURE_SEARCH_INDEX")

st.set_page_config(page_title="AI ê°ì • ì½”ì¹˜", layout="wide")

# -------------------------------
# ë‹µë³€ ê°ì • ì¶”ì¶œ
# -------------------------------
def return_new_emotion(response_text):
    emotion_extract_prompt = f"""
        ë‹¤ìŒ ì–´ì‹œìŠ¤í„´íŠ¸ì˜ ë‹µë³€ì„ ì½ê³ , ì‚¬ìš©ìì˜ í˜„ì¬ ê°ì •ì„ ì¶”ë¡ í•´ì¤˜.
        ê°€ëŠ¥í•œ ê°’: í–‰ë³µ, í‰ì˜¨, ìŠ¬í””, ë¶„ë…¸, í”¼ë¡œ, ë¶ˆì•ˆ
        ì¶œë ¥ì€ ê°ì • ë‹¨ì–´ë§Œ ë°˜í™˜í•´.
        ë‹µë³€: "{response_text}"
    """
    emotion_response = openai.chat.completions.create(
        model="dev-gpt-4.1-mini",
        messages=[{"role": "system", "content": emotion_extract_prompt}],
        temperature=0.7
    )
    emotion =  emotion_response.choices[0].message.content.strip()

    emotion_map = {
        "í–‰ë³µ": "ğŸ˜Š í–‰ë³µ",
        "í‰ì˜¨": "ğŸ˜ í‰ì˜¨",
        "ìŠ¬í””": "ğŸ˜¢ ìŠ¬í””",
        "ë¶„ë…¸": "ğŸ˜  ë¶„ë…¸",
        "í”¼ë¡œ": "ğŸ˜© í”¼ë¡œ",
        "ë¶ˆì•ˆ": "ğŸ˜¨ ë¶ˆì•ˆ"
    }

    if emotion in emotion_map:
        st.session_state["emotion"] = emotion_map[emotion]
        selected_emotion = emotion_map[emotion]

# -------------------------------
# ì¶”ì²œ ì½˜í…ì¸  ì œê³µ
# -------------------------------
def recommend_content_for_emotion(user_input):

    # ì„ë² ë”©
    embedding_url = f"{embedding_azure_endpoint}/openai/deployments/{embedding_deployment}/embeddings?api-version={embedding_api_version}"
    embedding_headers = {
        "api-key": embedding_api_key,
        "Content-Type": "application/json"
    }
    max_length = 2000
    short_text = user_input[:max_length]
    embedding_data = {"input": short_text}
    embedding_response = requests.post(embedding_url, headers=embedding_headers, json=embedding_data)
    query_vector = embedding_response.json()["data"][0]["embedding"]

    # Azure AI Searchì— ë²¡í„° ê²€ìƒ‰ ìš”ì²­
    search_url = f"{search_endpoint}/indexes/{search_index}/docs/search?api-version=2023-07-01-Preview"
    search_headers = {
        "api-key": search_api_key,
        "Content-Type": "application/json"
    }

    search_body = {
        "vector": {
            "value": query_vector,
            "fields": "text_vector",
            "k": 6
        },
        "select": "chunk"
    }
    
    vector_response = requests.post(search_url, headers=search_headers, json=search_body)
    search_results = vector_response.json().get("value", [])
    return "\n".join([f"- {doc['chunk']}" for doc in search_results])

# -------------------------------
# GPT í”„ë¡¬í¬íŠ¸ ì‚¬ìš©
# -------------------------------
def use_openAI(user_input, recommended_texts):
    prompt = (
        f"ë‹¹ì‹ ì€ ë”°ëœ»í•œ ê°ì • ì½”ì¹˜ì…ë‹ˆë‹¤."
        f"ë‹¤ìŒ ë‚´ìš©ì€ ì‚¬ìš©ìì˜ ì…ë ¥ê°’ì…ë‹ˆë‹¤. í•´ë‹¹ ë‚´ìš©ì„ ê¸°ë°˜ìœ¼ë¡œ ê°ì •ì„ ë¶„ì„í•˜ê³ , ê°ì • ì½”ì¹­ì„ í•´ì£¼ì„¸ìš”.\n"
        f"ë˜í•œ ì‘ë‹µì„ ìœ„í•´ ì…ë ¥ì— ë¯¼ê°í•˜ê±°ë‚˜ ì˜¤í•´ë  ìˆ˜ ìˆëŠ” í‘œí˜„ì´ ìˆë”ë¼ë„, ê·¸ëŒ€ë¡œ ë°˜ë³µí•˜ì§€ ë§ê³  ì•ˆì „í•œ ì–¸ì–´ë¡œ ë³€í™˜í•´ì„œ ì‘ë‹µí•˜ì„¸ìš”.\n"
        f"---\n"
        f"{user_input}\n"
        f"---\n"
        f"ì•„ë˜ì—ëŠ” Azure Searchì—ì„œ ë°˜í™˜ëœ ì½˜í…ì¸  ëª©ë¡ì´ ìˆìŠµë‹ˆë‹¤. ê° ì½˜í…ì¸ ì—ëŠ” emotion ê°’ì´ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤.\n"
        f"ë°˜ë“œì‹œ ì´ emotion ê°’ì„ í™•ì¸í•˜ì—¬, ì‚¬ìš©ìì˜ í˜„ì¬ ê°ì •ê³¼ ì¼ì¹˜í•˜ëŠ” ì½˜í…ì¸ ë§Œ ì„ ë³„í•´ ì‘ë‹µì— í™œìš©í•˜ì„¸ìš”.\n"
        f"---\n"
        f"{recommended_texts}\n"
        f"---\n"
        f"ì‘ë‹µì„ êµ¬ì„±í•  ë•ŒëŠ”:\n"
        f"1. ì‚¬ìš©ìì˜ ê°ì •ì„ ë¨¼ì € ê³µê°í•´ ì£¼ì„¸ìš”.\n"
        f"2. ê²€ìƒ‰ëœ ì½˜í…ì¸  ì¤‘ emotionì´ ì‚¬ìš©ìì˜ ê°ì •ê³¼ ì¼ì¹˜í•˜ëŠ” ê²ƒë§Œ ê³¨ë¼ ê°„ë‹¨íˆ ì†Œê°œí•˜ì„¸ìš”.\n"
        f"3. í•„ìš”í•˜ë‹¤ë©´ ì¶”ê°€ì ì¸ ì™¸ë¶€ ì½˜í…ì¸ (ìœ íŠœë¸Œ ì˜ìƒ, ê¸€ê·€, ì‹œ, ê°„ë‹¨í•œ ê²Œì„ ë§í¬ ë“±)ë¥¼ ê°„ë‹¨í•œ ì„¤ëª…ê³¼ í•¨ê»˜ URLë¡œ ì¶”ì²œí•˜ì„¸ìš”.\n"
        f"4. ì „ì²´ í†¤ì€ ë”°ëœ»í•˜ê³  ì½”ì¹­í•˜ëŠ” ë“¯í•œ ì–´ì¡°ë¡œ ìœ ì§€í•˜ì„¸ìš”."
    )
 
    messages = [{"role": "system", "content": prompt}] + st.session_state.chat_history
    print(messages)

    response = openai.chat.completions.create(
        model="dev-gpt-4.1-mini",
        messages=messages,
        temperature=0.7
    )

    return response.choices[0].message.content

# -------------------------------
# í™”ë©´ ì „í™˜ ìƒíƒœ ê´€ë¦¬
# -------------------------------
if "page" not in st.session_state:
    st.session_state.page = "main"

# -------------------------------
# ë©”ì¸ í˜ì´ì§€
# -------------------------------
if st.session_state.page == "main":
    st.title("ğŸ§  AI ê°ì • ì½”ì¹˜")
    st.subheader("ì˜¤ëŠ˜ ë‹¹ì‹ ì˜ ê°ì •ì€ ì–´ë–¤ê°€ìš”?")

    emotion = st.radio("ê°ì •ì„ ì„ íƒí•´ì£¼ì„¸ìš”:", ["ğŸ˜Š í–‰ë³µ", "ğŸ˜ í‰ì˜¨", "ğŸ˜¢ ìŠ¬í””", "ğŸ˜  ë¶„ë…¸", "ğŸ˜© í”¼ë¡œ", "ğŸ˜¨ ë¶ˆì•ˆ"])

    if st.button("ì½”ì¹­ ì‹œì‘í•˜ê¸°"):
        st.session_state["emotion"] = emotion
        st.session_state["page"] = "chat"
        st.stop()

# -------------------------------
# ì±—ë´‡ í˜ì´ì§€
# -------------------------------
elif st.session_state.page == "chat":
    selected_emotion = st.session_state.get("emotion", None)

    if not selected_emotion:
        st.warning("ê°ì •ì´ ì„ íƒë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ë©”ì¸ í™”ë©´ìœ¼ë¡œ ëŒì•„ê°‘ë‹ˆë‹¤.")
        st.session_state.page = "main"
        st.rerun()

    st.info(f"ğŸ§  ì„ íƒí•œ ê°ì •: **{selected_emotion}**")
    st.title("ğŸ’¬ ê°ì • ì½”ì¹­ ì±—ë´‡")

    if "chat_history" not in st.session_state:
        st.session_state.chat_history = []

    user_input = st.chat_input("ì§€ê¸ˆ ì–´ë–¤ ê¸°ë¶„ì´ì‹ ê°€ìš”?")

    # -------------------------------
    # ì±—ë´‡ ì˜ì—­
    # -------------------------------
    if user_input:
        st.session_state.chat_history.append({"role": "user", "content": user_input})

        with st.spinner("ğŸ§  ê°ì • ì½”ì¹­ ë¶„ì„ ì¤‘..."):

            recommended_texts = recommend_content_for_emotion(user_input)

            reply = use_openAI(user_input, recommended_texts)

        return_new_emotion(reply)

        st.session_state.chat_history.append({"role": "assistant", "content": reply})

    # í™”ë©´ì— í‘œì‹œ
    for msg in st.session_state.chat_history:
        with st.chat_message(msg["role"]):
            st.markdown(msg["content"])

    # -------------------------------
    # ì²¨ë¶€ ì˜ì—­
    # -------------------------------
    if "upload_key" not in st.session_state:
        st.session_state["upload_key"] = "1"

    with st.expander("ğŸ“ íŒŒì¼ ë° URL ì²¨ë¶€"):
        uploaded_excel = st.file_uploader("ì—‘ì…€ íŒŒì¼ ì—…ë¡œë“œ", type=["xlsx"], key="excel_" + st.session_state["upload_key"])
        uploaded_video = st.file_uploader("ë™ì˜ìƒ ì—…ë¡œë“œ", type=["mp4", "mov", "avi"], key="video_" + st.session_state["upload_key"])
        url_input = st.text_input("ğŸ”— URL ì…ë ¥ (ë©”ì¼, ë¬¸ì„œ ë“±)", key="url_" + st.session_state["upload_key"])

    text = ""
    sources = []

    # -------------------------------
    # ì—‘ì…€ ì²¨ë¶€ (ë©”ì‹ ì €)
    # -------------------------------
    if uploaded_excel:
        df = pd.read_excel(uploaded_excel)
        sources.append("ì—‘ì…€")
        text = " ".join(df.astype(str).fillna("").values.flatten())

        st.session_state.chat_history.append({
            "role": "user",
            "content": f"ì—‘ì…€ì œëª© : {uploaded_excel.name}  \nì—‘ì…€ë‚´ìš©  \n{text}"
        })

        with st.spinner("ğŸ§  ê°ì • ì½”ì¹­ ë¶„ì„ ì¤‘..."):

            recommended_texts = recommend_content_for_emotion(text)

            try:
                reply = use_openAI(text, recommended_texts)
                

                st.session_state.chat_history.append({"role": "assistant", "content": reply})

                # í™”ë©´ì— í‘œì‹œ
                with st.chat_message("assistant"):
                    st.success("âœ… ë¶„ì„ ì™„ë£Œ!")
                    st.markdown("ğŸ§  AI ì½”ë©˜íŠ¸:")

                    for line in reply.split("\n"):
                        if "http" in line:
                            parts = line.split("http")
                            description = parts[0].strip("-â€¢: ")
                            url = "http" + parts[1].strip()
                            st.markdown(f"**{description}** ğŸ‘‰ [ë°”ë¡œê°€ê¸°]({url})")
                        else:
                            st.markdown(line)
                
                return_new_emotion(reply)

                st.session_state["upload_key"] = str(int(st.session_state["upload_key"]) + 1)

                st.rerun()

            except openai.BadRequestError as e:
            # Azure OpenAI ì½˜í…ì¸  í•„í„°ì— ê±¸ë¦° ê²½ìš°
                st.markdown("âš ï¸ ì…ë ¥ì— ë¯¼ê°í•œ í‘œí˜„ì´ í¬í•¨ë˜ì–´ ì‘ë‹µì´ ì œí•œë˜ì—ˆìŠµë‹ˆë‹¤. í‘œí˜„ì„ ì¡°ê¸ˆ ë°”ê¿” ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")

            uploaded_excel = None  # ì—…ë¡œë“œ ì´ˆê¸°í™”
            st.session_state["uploaded_excel"] = None

    # -------------------------------
    # ë™ì˜ìƒ ì²¨ë¶€ (ì–¼êµ´ì¸ì‹, ìŒì„±ì¸ì‹)
    # -------------------------------
    if uploaded_video and "video_processed" not in st.session_state:
        st.session_state.video_processed = True

        with open("temp_video.mp4", "wb") as f:
            f.write(uploaded_video.read())
        video_path = "temp_video.mp4"

        cap = cv2.VideoCapture(video_path)
        frame_count = 0
        emotions = []

        max_frames = 100
        progress_bar = st.progress(0)
        status_text = st.empty()

        while cap.isOpened():
            ret, frame = cap.read()
            if not ret or frame_count >= max_frames:
                break

            try:
                result = DeepFace.analyze(frame, actions=['emotion'], enforce_detection=False)
                emotions.append(result[0]['dominant_emotion'])
            except:
                pass

            frame_count += 1
            progress_bar.progress(frame_count / max_frames)
            status_text.text(f"ğŸ” ê°ì • ë¶„ì„ ì¤‘... ({frame_count}/{max_frames} í”„ë ˆì„)")

        cap.release()
        progress_bar.empty()
        status_text.text("âœ… ì–¼êµ´ ê°ì • ë¶„ì„ ì™„ë£Œ!")

        # ìŒì„± ì¸ì‹
        model = whisper.load_model("base")

        audio_path = "audio.wav"
        subprocess.run(["ffmpeg", "-y", "-i", video_path, "-vn", "-acodec", "pcm_s16le", "-ar", "16000", "-ac", "1", audio_path])

        result = model.transcribe(audio_path)
        transcript = result["text"]

        emotion_summary = Counter(emotions).most_common()
        dominant_emotion = emotion_summary[0][0] if emotion_summary else "unknown"

        text = f"ì˜ìƒì—ì„œ ì¶”ì •ëœ ê°ì •ì€ '{dominant_emotion}'ì…ë‹ˆë‹¤.  \n"
        #text += f"ì‚¬ìš©ìì˜ ìŒì„± ë‚´ìš©: {transcript}  \n"
        sources.append("ë™ì˜ìƒ(ì–¼êµ´)")
        #sources.append("ë™ì˜ìƒ(ìŒì„±)")
        
        st.session_state.chat_history.append({
            "role": "user",
            "content": f"ì˜ìƒì œëª© : {uploaded_video.name}  \nì˜ìƒë‚´ìš©  \n{text}"
        })

        with st.spinner("ğŸ§  ê°ì • ì½”ì¹­ ë¶„ì„ ì¤‘..."):

            recommended_texts = recommend_content_for_emotion(text)

            try:
                reply = use_openAI(text, recommended_texts)

                st.session_state.chat_history.append({"role": "assistant", "content": reply})

                st.markdown(f"ğŸ“ ë¶„ì„ ëŒ€ìƒ: {', '.join(sources)}")
                st.markdown("ğŸ§  AI ì½”ë©˜íŠ¸:")

                # í™”ë©´ì— í‘œì‹œ
                for line in reply.split("\n"):
                    if "http" in line:
                        parts = line.split("http")
                        description = parts[0].strip("-â€¢: ")
                        url = "http" + parts[1].strip()
                        st.markdown(f"**{description}** ğŸ‘‰ [ë°”ë¡œê°€ê¸°]({url})")
                    else:
                        st.markdown(line)

                return_new_emotion(reply)

                # ğŸ”‘ ì²¨ë¶€ ì˜ì—­ ì´ˆê¸°í™”
                st.session_state["upload_key"] = str(int(st.session_state["upload_key"]) + 1)

                st.rerun()
            except openai.BadRequestError as e:
            # Azure OpenAI ì½˜í…ì¸  í•„í„°ì— ê±¸ë¦° ê²½ìš°
                st.error("âš ï¸ ì…ë ¥ì— ë¯¼ê°í•œ í‘œí˜„ì´ í¬í•¨ë˜ì–´ ì‘ë‹µì´ ì œí•œë˜ì—ˆìŠµë‹ˆë‹¤. í‘œí˜„ì„ ì¡°ê¸ˆ ë°”ê¿” ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")
                
            uploaded_video = None
            if "video_processed" in st.session_state:
                del st.session_state["video_processed"]
    # -------------------------------
    # URL ì²¨ë¶€ (ë©”ì¼í•¨)
    # -------------------------------    
    if url_input:
        try:
            with st.spinner("ğŸ§  ê°ì • ì½”ì¹­ ë¶„ì„ ì¤‘..."):
                # 1. URL ì ‘ì† ë° HTML ê°€ì ¸ì˜¤ê¸°
                response = requests.get(url_input)
                response.encoding = "utf-8"
                soup = BeautifulSoup(response.text, "html.parser")

                # 2. ë³¸ë¬¸ í…ìŠ¤íŠ¸ ì¶”ì¶œ
                text = soup.get_text(separator=" ", strip=True)

                st.session_state.chat_history.append({
                    "role": "user",
                    "content": f"URL : {url_input}  \në‚´ìš©  \n{text}"
                })

                recommended_texts = recommend_content_for_emotion(text)

                reply = use_openAI(text, recommended_texts)

                st.session_state.chat_history.append({"role": "assistant", "content": reply})

                return_new_emotion(reply)

                # í™”ë©´ì— í‘œì‹œ
                with st.chat_message("assistant"):
                    st.success("âœ… ë¶„ì„ ì™„ë£Œ!")
                    st.markdown("ğŸ§  AI ì½”ë©˜íŠ¸:")

                    for line in reply.split("\n"):
                        if "http" in line:
                            parts = line.split("http")
                            description = parts[0].strip("-â€¢: ")
                            url = "http" + parts[1].strip()
                            st.markdown(f"**{description}** ğŸ‘‰ [ë°”ë¡œê°€ê¸°]({url})")
                        else:
                            st.markdown(line)

                    # ğŸ”‘ ì²¨ë¶€ ì˜ì—­ ì´ˆê¸°í™”
                    st.session_state["upload_key"] = str(int(st.session_state["upload_key"]) + 1)

                    st.rerun()

        except Exception as e:
            st.error(f"í¬ë¡¤ë§ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        except openai.BadRequestError as e:
        # Azure OpenAI ì½˜í…ì¸  í•„í„°ì— ê±¸ë¦° ê²½ìš°
            st.markdown("âš ï¸ ì…ë ¥ì— ë¯¼ê°í•œ í‘œí˜„ì´ í¬í•¨ë˜ì–´ ì‘ë‹µì´ ì œí•œë˜ì—ˆìŠµë‹ˆë‹¤. í‘œí˜„ì„ ì¡°ê¸ˆ ë°”ê¿” ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")

        url_input = ""
        key = "url_" + st.session_state["upload_key"]
        if key in st.session_state:
            del st.session_state[key]


